# A personal assistant of sorts
A final product should be a voice assistant server running smooth on local machine, with access to bespoke tools.

The platform for running the solution is Docker.

To use the assistant, you need access to Meta Llama gated models in Hugging Face hub.

Once granted, generate an [access token](https://huggingface.co/docs/hub/security-tokens) and store the token
in a text file *hf_token.txt* inside the project folder.

### This project is used for learning different AI types

- Speech recognition
- Text to speech
- Chat
- Inference on GPU

### Todo

- **Kinda done** Increase inference server performance
- **Kinda done, needs refinement** Fix the robotic voice
- Streaming
- Add agentic capability
- Create tools


**Built with Llama**
