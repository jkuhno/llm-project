services:
  langgraph-server:
    build:
      context: ./api_server
      dockerfile: Dockerfile
      target: langgraph
    init: true
    env_file: ".env"
    volumes:
      - type: bind
        source: .
        target: /usr/src/app/
    environment:
      - PYTHONPATH=/usr/src/app
    networks:
      - app-network
    ports:
      - 2024:2024
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
  db:
    image: pgvector/pgvector:pg17
    restart: unless-stopped
    volumes:
      - pgdata:/var/lib/postgresql/data
      - ./postgres/vector_init.sql:/docker-entrypoint-initdb.d/vector_init.sql
    environment:
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_DB=${POSTGRES_DB}
    networks:
      - app-network
    ports:
      - 5432:5432
  vllm-server:
    image: vllm/vllm-openai:v0.7.0
    runtime: nvidia
    volumes:
      - ./.cache/huggingface:/root/.cache/huggingface
    environment:
      HUGGING_FACE_HUB_TOKEN: "${HF_TOKEN}"
    ipc: host
    # --model meta-llama/Llama-3.2-3B-Instruct
    command: >
      --model ${VLLM_MODEL}
      --max-model-len 30000
      --enable-auto-tool-choice
      --tool-call-parser llama3_json
    networks:
      - app-network
    ports:
      - 8000:8000
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
networks:
  app-network:
    driver: bridge
volumes:
  pgdata:

